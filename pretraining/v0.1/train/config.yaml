defaults:
  - train: train_aquila_3b 
  - _self_

experiment:
  exp_name: aquila_3b_exp02
  exp_dir: ${experiment.exp_name}
  cmds:
    before_start: export PYTHONPATH=/usr/local/corex-4.1.1/lib64/python3/dist-packages
  task:
    type: train
    backend: megatron
    entrypoint: ./flagscale/train/train_aquila.py
  runner:
    backend: torchrun
    rdzv_backend: static
    ssh_port: 22
    nnodes: 8
    nproc_per_node: 16 
    hostfile: ./hostfile
  envs:
    CUDA_VISIBLE_DEVICES: 0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15
    #CUDA_VISIBLE_DEVICES: 0,1,2,3,4,5,6,7
    CUDA_DEVICE_MAX_CONNECTIONS: 1
    CCL_IB_DISABLE: 0
    NCCL_IB_CUDA_SUPPORT: 1
    NCCL_IB_GID_INDEX: 0
    #TORCH_NCCL_USE_COMM_NONBLOCKING: 1
    OMP_NUM_THREADS: 4
    ENABLE_FLASH_ATTENTION_WITH_IXDNN: 0
    NCCL_NET_PLUGIN: none
    #NCCL_SHM_DISABLE=1
    NCCL_ALGO: Ring
    NCCL_P2P_NET_CHUNKSIZE: 1048576
    NCCL_CHUNK_SIZE: 1048576
    NCCL_BUFFSIZE: 8388608
    NCCL_MAX_NCHANNELS: 4
    NCCL_MIN_NCHANNELS: 4
    NCCL_MAX_P2P_NCHANNELS: 1
    NCCL_PROTO: Simple
    NCCL_NET_SHARED_BUFFERS: 0
    NCCL_P2P_LL_THRESHOLD: 0
    IXCCL_MIX_NV: 1
    IXCCL_FUSED_ENABLE: 0
    NCCL_IB_DISABLE: 0
    NCCL_IB_HCA: mlx5_2,mlx5_8
    A800:
      CUDA_VISIBLE_DEVICES: 0,1,2,3,4,5,6,7
      NCCL_SOCKET_IFNAME: eth0
      GLOO_SOCKET_IFNAME: eth0
      OPAL_PREFIX: /opt/hpcx/ompi
      PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION: python
      LD_LIBRARY_PATH: /usr/local/lib/python3.10/dist-packages/torch/lib:/usr/local/lib/python3.10/dist-packages/torch_tensorrt/lib:/usr/local/cuda/compat/lib:/usr/local/nvidia/lib:/usr/local/nvidia/lib64
      PATH: /usr/local/nvm/versions/node/v16.20.2/bin:/usr/local/lib/python3.10/dist-packages/torch_tensorrt/bin:/usr/local/mpi/bin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/local/ucx/bin:/opt/tensorrt/bin
    #PATH: /usr/local/nvm/versions/node/v16.20.2/bin:/usr/local/lib/python3.10/dist-packages/torch_tensorrt/bin:/usr/local/mpi/bin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/local/ucx/bin:/opt/tensorrt/bin
    #LD_LIBRARY_PATH: /usr/local/lib/python3.10/dist-packages/torch/lib:/usr/local/lib/python3.10/dist-packages/torch_tensorrt/lib:/usr/local/cuda/compat/lib:/usr/local/nvidia/lib:/usr/local/nvidia/lib64 
    B150:
      NUMEXPR_MAX_THREADS: 64
      NCCL_SOCKET_IFNAME: ibs2
      GLOO_SOCKET_IFNAME: ibs2
      LD_LIBRARY_PATH: /usr/local/corex/lib:/usr/local/corex/lib64:/usr/local/corex-4.1.1/lib64:/usr/local/openmpi/lib:/usr/local/lib
      PATH: /usr/local/corex/bin/:/root/.cargo/bin:/usr/local/corex-4.1.1/bin:/usr/local/corex-4.1.1/lib64/python3/dist-packages/bin:/usr/local/openmpi/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin
action: run

hydra:
  run:
    dir: ${experiment.exp_dir}/hydra 
